export const previousProjects = [
  { 
    title: "Tetris game", 
    deployment_link: "https://nlie2.github.io/Tetris/", 
    description: "A solo project in which I built a game in plain JavaScript, deployed with Netlify." 
  },
  { 
    title: "Can I wear short pants today", 
    deployment_link: "https://caniwearshortpants.netlify.app/", 
    description: "A web application making use of a weather API, which tells users whether it is warm enough to wear short pants. It was a pair project and I focused mostly on the React components and API calls for this project." 
  },
  { 
    title: "Stock Portfolio Analyzer", 
    deployment_link: "https://stock-portfolio-analyzer-cc275ea5067c.herokuapp.com/", 
    description: "A Full-Stack Web application that allows users to determine the Networth progression of their stock portfolio. The backend is written in Python/Django and the frontend in React." 
  },
  { 
    title: "SEI quizz app", 
    deployment_link: "https://quizzapp-88d607683c8a.herokuapp.com/", 
    description: "A web application using Express and React, allowing students to share knowledge of a common course. I mostly worked on connecting front- and backend, and creating the API for this project." 
  }
];

export const currentProjects = [
  { 
    title: "(current work in progress) Predicting Jailbreak Success: Do Different Attack Mechanisms Exploit Similar Mechanisms?", 
    authors: "Nathalie M Kirch, Severin Field, Stephen Casper",  
    description: "Many studies have demonstrated different jailbreaking and attack methods that manipulate LLMs to produce harmful outputs. This has been central to modern robustness research in revealing vulnerabilities of current alignment methods. However, underlying mechanisms of these attacks and their similarity across different attack methods remain poorly understood. In this work, we analyze different attack methods. Using different probing techniques, we attempt to predict jailbreak success based on prompt latents alone and investigate how linearly jailbreak success is represented. Furthermore, we experiment with causal intervention white-box jailbreak to increase the attack success rate of malicious prompts."
  }, 
  { 
    title: "(current work in progress) TRIAGE : Ethical Benchmarking of AI Models Through Mass Casualty Simulations", 
    authors: "Nathalie M Kirch, Konstantin Hebenstreit, Matthias Samwald",  
    description: "We present the TRIAGE Benchmark: a novel machine ethics (ME) benchmark which incorporates triage training scenarios used to prepare medical professionals for ethical decision-making during mass casualty events. These scenarios are real-world ethical dilemmas with solutions that are derived from socially agreed-upon principles offering a more realistic alternative to annotation-based ME benchmarks. By incorporating a variety of different prompting styles, TRIAGE allows us to test the performance of our models across a variety of different contexts. Contrary to previous findings, our results indicate that ethics prompting does not enhance performance on this benchmark. Moreover, we observe that jailbreaking prompts can significantly degrade model performance and alter their relative rankings. While we find that open-source models tend to make more morally grave errors, our comparison of modelsâ€™ best- and worst-case performances suggests that general capability is not always a reliable predictor of good ethical decision-making. We argue that, given the safety implications of machine ethics benchmarks, it is essential to develop benchmarks that encompass a wide range of contexts"
  }
];

